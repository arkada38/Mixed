---
title: "Анализ данных"
author: "Arkadiy Kuznetsov"
output: 
  html_document: 
    fig_height: 6
    fig_width: 8
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regression analysis - Регрессионный анализ
[ENG](https://en.wikipedia.org/wiki/Regression_analysis) [РУС](https://ru.wikipedia.org/wiki/Регрессионный_анализ)

*Регрессионный анализ* -- статистический метод исследования влияния одной или нескольких независимых переменных 
<code>X<sub>1</sub>, X<sub>2</sub>, ... , X<sub>p</sub></code> на зависимую переменную  `Y`  

#### Цели регрессионного анализа

1. Определение степени детерминированности вариации критериальной (зависимой) переменной предикторами (независимыми переменными)
2. Предсказание значения зависимой переменной с помощью независимой(-ых)
3. Определение вклада отдельных независимых переменных в вариацию зависимой

*Регрессионный анализ* нельзя использовать для определения наличия связи между переменными, поскольку наличие такой связи и есть предпосылка для применения анализа.

### Linear regression - Линейная регрессия
[ENG](https://en.wikipedia.org/wiki/Linear_regression) [РУС](https://ru.wikipedia.org/wiki/Линейная_регрессия)

*Линейная регрессия* -- используемая в статистике регрессионная модель зависимости одной (объясняемой, зависимой) переменной `y` от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) `x` с **линейной** функцией зависимости.

#### Подключение библиотек

```{r}
library(knitr)
library(ggplot2)
```

#### Обзор

Рассмотрим стандартный набор данных `Formaldehyde`
```{r, echo=FALSE}
kable(head(Formaldehyde))
```
```{r}
str(Formaldehyde)
```


Построим график
```{r}
ggplot(Formaldehyde, aes(x = carb, y = optden)) +
  geom_point(size = 2.5)
```

#### Построение модели

Проведем регрессионный анализ для зависимой переменной `optden` с независимой переменной `carb`
```{r}
fit <- lm(optden ~ carb, data = Formaldehyde)
```
Результат:
```{r}
summary(fit)
```
Особое внимание обращаем на коэффициенты
```{r}
fit$coefficients
```
Подставив их в уравнение регрессии, получим выражение: `optden = 0.005 + 0.876 * carb`

Помимо коэффициентов, R показывает нам *величины ошибок*, или *стандартного отклонения*, для каждого коэффициента. Например, нам может быть интересно, объясняют ли вообще хоть что-нибудь наши коэффициенты.

Чтобы проверить это, мы, выдвигаем нулевую гипотезу, что, коэффициент `0.876` является лишь результатом погрешности и его значением можно пренебречь. Для проверки такой гипотезы, используется *t-критерий Стьюдента*. R за нас делает всю работу, вычисляя как саму величину *t* так и степень значимости нашей гипотезы `Pr(>|t|)`. Так, в нашем случае величина `3.41e-07` означает что мы на `100 * (1 - 3.41e-07) = 99.99997%` уверены в том, что член `carb` в нашем выражении отличен от нуля.

Далее мы можем проверить, насколько точно наша модель описывает данные. Для этого используются коэффициенты <code>R<sup>2</sup></code>. Чем ближе величина этих значений к 1, тем лучше. 1 это идеальный результат, означающий, что модель на 100% описывает данные.

И, наконец, последнее, что мы можем проверить, это то, насколько предсказываемая величина зависит от предикторов. Для этого выдвигается нулевая гипотеза, что предсказываемая величина вообще не зависит от предикторов. Для этой гипотезы определяется *p*-значение. В нашем случае, оно получилось равным `3.409e-07`. Т.е. мы можем быть уверенны на `99.99997%`, что предсказываемая величина действительно зависит от предикторов. Обычно, имеет смысл смотреть на этот параметр в первую очередь, ведь он определяет, насколько вообще наша модель адекватна.

Построим график c линейной регрессией
```{r}
ggplot(Formaldehyde, aes(x = carb, y = optden)) +
  geom_point(size = 2.5) +
  ggtitle("optden ~ carb \n optden = 0.005 + 0.876 * carb") +
  geom_abline(aes(intercept = fit$coefficients[1], slope = fit$coefficients[2]), color = "blue", size = 1)
```

#### Прогнозирование

Создадим data.frame со значениями `carb`, для которых мы хотим получить значения `optden`
```{r}
newdata <- data.frame(carb = c(.2, .4, .8))
```
Добавим к data.frame значения `optden`
```{r}
newdata$optden <- predict(fit, newdata)
```
Построим график со старыми, по которым модель обучалась, и новыми значениями
```{r}
ggplot(Formaldehyde, aes(x = carb, y = optden)) +
  geom_point(size = 2.5) +
  ggtitle("optden ~ carb \n optden = 0.005 + 0.876 * carb") +
  geom_abline(aes(intercept = fit$coefficients[1], slope = fit$coefficients[2]), color = "blue", size = 1) +
  geom_point(data = newdata, size = 2.5, colour = "red")
```


#### Ссылки
 * [Линейная регрессия с примерами на R](http://www.algorithmist.ru/2011/04/linear-regression-with-examples-in-r.html)



## Links
* [R Markdown](http://rmarkdown.rstudio.com/lesson-1.html)
* [R Markdown Cheat Sheet](https://www.rstudio.org/links/r_markdown_cheat_sheet)
* [R Markdown Reference Guide](https://www.rstudio.org/links/r_markdown_reference_guide)
* [HTML Documents](http://rmarkdown.rstudio.com/html_document_format.html)
